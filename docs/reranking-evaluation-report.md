# リランキング evaluate/check 修正 & 評価レポート

## 背景

リランキング実装 (#432) で重みパラメータを変えても `evaluate` / `check` の結果が変わらないバグがあった。

## 原因

2箇所で `convert_k_best`（リランキング適用済み）を経由していなかった。

### 1. check.rs

k-best モードで `engine.graph_resolver.resolve_k_best(&lattice, k)` を直接呼んでおり、リランキングが適用されていなかった。

```rust
// Before
let paths = engine.graph_resolver.resolve_k_best(&lattice, k)?;

// After
let paths = engine.convert_k_best(yomi, None, k)?;
```

### 2. evaluate.rs

1-best 判定に `engine.convert()` を使っていたため、リランキングで順位が変わっても Good/Bad に反映されなかった。

```rust
// Before: convert で 1-best、不一致時に別途 convert_k_best
let result = engine.convert(yomi, Some(&force_ranges))?;

// After: convert_k_best 1回で両方判定
let k_results = engine.convert_k_best(yomi, Some(&force_ranges), k_best)?;
let got = k_results.first().map(|p| /* 先頭パスから surface を取得 */);
```

## 修正内容

- PR: #433
- `check.rs`: k-best ブランチで `convert_k_best` を使用するように変更
- `evaluate.rs`: `convert` → `convert_k_best` の先頭パスで 1-best 判定するように変更

## 評価結果

### 条件

- コーパス: anthy-corpus (corpus.0〜5.txt, 全 11,233 件)
- 辞書: SKK-JISYO.L
- モデル: akaza-default-model
- k-best: 5 (デフォルト)

### 結果

| unknown-bigram-weight | Good | Top-5 | Bad | 再現率 |
|---|---|---|---|---|
| **1.0 (default)** | **6,427** | **467** | **4,339** | **92.51%** |
| 0.3 | 5,931 | 963 | 4,339 | 91.46% |
| 0.1 | 5,780 | 1,114 | 4,339 | 91.23% |

### 分析

- **重みパラメータの変更が evaluate に正しく反映されている**ことを確認した
- Bad は全パターン同じ (4,339) — Top-5 にも入らないものは重みを変えても変わらない
- Good + Top-5 の合計も同じ (6,894) — リランキングで Top-5 内の順位が入れ替わっている
- unknown-bigram-weight を下げると Good が減り Top-5 が増える
  - 未知 bigram のコストを軽くすると、未知語を含む分割が選ばれやすくなり精度が低下
- **デフォルト (1.0) が現時点では最良**

### corpus.2.txt のみでの結果 (参考)

| unknown-bigram-weight | Good | Top-5 | Bad | 再現率 |
|---|---|---|---|---|
| **1.0 (default)** | **13** | **4** | **61** | **71.85%** |
| 0.3 | 13 | 4 | 61 | 70.76% |
| 0.1 | 12 | 5 | 61 | 70.41% |

## length-weight 評価

### 粗探索 (0〜10.0)

| length-weight | Good | Top-5 | Bad | 再現率 | Good差分 |
|---|---|---|---|---|---|
| 0 (baseline) | 6,427 | 467 | 4,339 | 92.51% | - |
| 0.1 | 6,428 | 466 | 4,339 | 92.51% | +1 |
| 0.5 | 6,438 | 456 | 4,339 | 92.56% | +11 |
| 1.0 | 6,462 | 432 | 4,339 | 92.61% | +35 |
| 2.0 | 6,472 | 422 | 4,339 | 92.64% | +45 |
| 3.0 | 6,473 | 421 | 4,339 | 92.62% | +46 |
| 5.0 | 6,438 | 456 | 4,339 | 92.51% | +11 |
| 10.0 | 6,350 | 544 | 4,339 | 92.33% | -77 |

- length-weight を上げるほど Good が増加し、2.0〜3.0 でピーク
- 5.0 以上では逆に悪化し、10.0 では baseline を下回る

### 詳細探索 (2.0〜3.0, 0.1刻み)

| length-weight | Good | Top-5 | Bad | 再現率 | Good差分 |
|---|---|---|---|---|---|
| 2.0 | 6,472 | 422 | 4,339 | 92.64% | +45 |
| 2.1 | 6,473 | 421 | 4,339 | 92.63% | +46 |
| 2.2 | 6,473 | 421 | 4,339 | 92.64% | +46 |
| **2.3** | **6,474** | **420** | **4,339** | **92.63%** | **+47** |
| 2.4 | 6,470 | 424 | 4,339 | 92.62% | +43 |
| 2.5 | 6,472 | 422 | 4,339 | 92.62% | +45 |
| 2.6 | 6,471 | 423 | 4,339 | 92.62% | +44 |
| 2.7 | 6,472 | 422 | 4,339 | 92.63% | +45 |
| 2.8 | 6,473 | 421 | 4,339 | 92.63% | +46 |
| 2.9 | 6,468 | 426 | 4,339 | 92.61% | +41 |
| 3.0 | 6,473 | 421 | 4,339 | 92.62% | +46 |

- **ピークは length-weight=2.3** (Good=6,474, +47)
- ただし 2.0〜3.0 の範囲で Good は 6,468〜6,474 (差6件) とほぼ横ばい
- この範囲ではパラメータに対して敏感ではなく、2.0〜3.0 のどこでもほぼ同等の改善

## 考察

### unknown-bigram-weight

- 単体での改善は難しい
  - 1.0 未満にすると悪化する
  - 1.0 を超えると元のモデルが学習したコストバランスを歪めることになる

### length-weight

- **length-weight=2.3 が最適値** (baseline比 Good+47, 再現率 92.51%→92.63%)
- トークン数の少ない（= 長い単位でまとめた）分割を優先することで精度向上
- 2.0〜3.0 の範囲で安定しており、ロバストなパラメータと言える
- 5.0 以上では過度にトークン数を減らそうとして逆効果

### 今後の方向

- length-weight のデフォルト値を 2.0〜2.5 程度に設定することを検討
- 複数の重みパラメータの組み合わせ探索
- コーパスを使った重みの自動チューニング
